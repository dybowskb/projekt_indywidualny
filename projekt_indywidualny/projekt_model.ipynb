{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e20af43",
   "metadata": {},
   "source": [
    "# Rozpoznawanie gatunków muzycznych za pomocą uczenia maszynowego\n",
    "## Tworzenie modelu\n",
    "#### Bartosz Dybowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1402bab",
   "metadata": {},
   "source": [
    "### 1. Wyodrębnienie cech z utworów i stworzenie tabeli z danymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fe2c8e",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a183203e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Ścieżka do folderu z plikami WAV\n",
    "folder_path = \"zbiór utworów\"\n",
    "\n",
    "# Listy przechowujące cechy i przypisane gatunki\n",
    "data = []\n",
    "genres = []\n",
    "\n",
    "# Iteracja po plikach w folderze\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        y, sr = librosa.load(file_path)\n",
    "        onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "        \n",
    "        # Wyodrębnienie cech\n",
    "        tempo = librosa.feature.tempo(onset_envelope=onset_env, sr=sr)  # Tempo \n",
    "        key, _ = librosa.beat.beat_track(y=y, sr=sr)  # Tonacja\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y).mean()  # Liczba przejść przez zero\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()  # Środek ciężkości widma\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean()  # Szerokość pasm spektralnych\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr).mean()  # Kontrast spektralny\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()  # Rolloff spektralny\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(y=y).mean()  # Płaskość spektralna\n",
    "        rms = librosa.feature.rms(y=y).mean()  # Skuteczna wartość średnia (RMS - Root Mean Square)\n",
    "        harmonic_to_noise = librosa.effects.harmonic(y).mean()  # Stosunek harmoniczności do szumu(Harmonic-to-Noise Ratio)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr).mean()  # Chromagram\n",
    "        chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr).mean()\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr).mean()  # Współczynniki cepstralne (MFCCs)\n",
    "        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)  # Częstotliwość fundamentalna (Pitch)\n",
    "        rhythmics = librosa.feature.tempogram(y=y, sr=sr).mean()  # Rytmika\n",
    "\n",
    "        # Dodanie cech do listy danych\n",
    "        data.append([tempo, key, zero_crossing_rate, spectral_centroid, spectral_bandwidth, \n",
    "                     spectral_contrast, spectral_rolloff, spectral_flatness, rms, harmonic_to_noise, \n",
    "                     chroma_stft, chroma_cens, mfcc, pitches.mean(), rhythmics])\n",
    "        \n",
    "        # Odczyt gatunku z nazwy pliku (nazwa pliku jest w formacie \"nazwaGatunku_numer.wav\")\n",
    "        genre = file_name.split('_')[0]\n",
    "        genres.append(genre)\n",
    "\n",
    "# Utworzenie ramki danych Pandas\n",
    "df = pd.DataFrame(data, columns=['tempo', 'key', 'zero_crossing_rate', 'spectral_centroid', 'spectral_bandwidth', \n",
    "                                 'spectral_contrast', 'spectral_rolloff', 'spectral_flatness', 'rms', 'harmonic_to_noise', \n",
    "                                 'chroma_stft', 'chroma_cens', 'mfcc', 'pitches', 'rhythmics'])\n",
    "\n",
    "# Dodanie kolumny z gatunkiem\n",
    "df['genre'] = genres  "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da42a4a",
   "metadata": {},
   "source": [
    "# Przekształcenie kolumny tempo na typ danych numeryczny\n",
    "df['tempo'] = df['tempo'].astype(float)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea8b5eb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Tabela z danymi\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2b21820c",
   "metadata": {},
   "source": [
    "### 2. Analiza i wybór cech (atrybutów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a52151e",
   "metadata": {},
   "source": [
    "# Tabela z samymi atrybutami (bez przypisanych klas)\n",
    "attributes_df = df.drop(columns=['genre'])\n",
    "attributes_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cce7cef",
   "metadata": {},
   "source": [
    "sns.pairplot(df, kind = \"scatter\", hue = \"genre\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8678da6",
   "metadata": {},
   "source": [
    "# Analiza korelacji\n",
    "correlation_matrix = attributes_df.corr()\n",
    "plt.figure(figsize=(12,9), dpi = 100)\n",
    "sns.heatmap(correlation_matrix, annot=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "05ab7e5a",
   "metadata": {},
   "source": [
    "Po analizie i dokonaniu wyboru atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "51d521ad",
   "metadata": {},
   "source": [
    "df_reduced = df.drop(columns=['spectral_contrast', 'chroma_cens', 'rhythmics', 'spectral_bandwidth'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1e3b8bc4",
   "metadata": {},
   "source": [
    "### 3. Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8d924732",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f628134d",
   "metadata": {},
   "source": [
    "def divide(dataframe, proportion):\n",
    "    dscr_lrn, dscr_test, dec_lrn, dec_test = train_test_split(dataframe.iloc[:, 0:-1], \n",
    "                                            dataframe.iloc[:, -1].astype('category').cat.codes, test_size = proportion, \n",
    "                                            stratify = dataframe.iloc[:, -1].astype('category').cat.codes, random_state=42)\n",
    "    return {'dscr_lrn':dscr_lrn, 'dscr_test':dscr_test, 'dec_lrn':dec_lrn, 'dec_test':dec_test}\n",
    "\n",
    "def verify(model, dscr_lrn, dscr_test, dec_lrn, dec_test, attrib):\n",
    "    model.fit(dscr_lrn.iloc[:, attrib], dec_lrn)\n",
    "    lrn_res = model.predict(dscr_lrn.iloc[:, attrib])\n",
    "    test_res = model.predict(dscr_test.iloc[:, attrib])\n",
    "    \n",
    "    mp = confusion_matrix(dec_lrn, lrn_res)\n",
    "    print('Macierz pomylek dla zbioru uczącego, dokładność:',np.sum(np.diag(mp))/np.sum(mp))\n",
    "    print(pd.crosstab(dec_lrn, lrn_res))\n",
    "    \n",
    "    mp = confusion_matrix(dec_test, test_res)\n",
    "    print('Macierz pomylek dla zbioru testowego, dokładność:',np.sum(np.diag(mp))/np.sum(mp))\n",
    "    print(pd.crosstab(dec_test, test_res))\n",
    "\n",
    "def lims(model, dscr_lrn, dscr_test, dec_lrn, dec_test, x, y, contour = 1):\n",
    "    if (contour == 1):    \n",
    "        model.fit(dscr_lrn.iloc[:, [x, y]], dec_lrn)\n",
    "        x_min = min(dscr_lrn.iloc[:, x].min(), dscr_test.iloc[:, x].min())\n",
    "        x_max = max(dscr_lrn.iloc[:, x].max(), dscr_test.iloc[:, x].max())\n",
    "        y_min = min(dscr_lrn.iloc[:, y].min(), dscr_test.iloc[:, y].min())\n",
    "        y_max = max(dscr_lrn.iloc[:, y].max(), dscr_test.iloc[:, y].max())\n",
    "        range_x = x_max - x_min\n",
    "        range_y = y_max - y_min\n",
    "        x_min = x_min - 0.1 * range_x\n",
    "        x_max = x_max + 0.1 * range_x\n",
    "        y_min = y_min - 0.1 * range_y\n",
    "        y_max = y_max + 0.1 * range_y       \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max - x_min) / 150), \n",
    "                    np.arange(y_min, y_max, (y_max - y_min) / 150))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "    plt.figure(dpi = 100)\n",
    "    if (contour == 1):\n",
    "        plt.contourf(xx, yy, Z, levels = 4, alpha = 0.2)\n",
    "    plt.scatter(dscr_lrn.iloc[:, x], dscr_lrn.iloc[:, y], c = dec_lrn, marker = '.')\n",
    "    plt.scatter(dscr_test.iloc[:, x], dscr_test.iloc[:, y], c = dec_test, marker = 'x') "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "29f4ef84",
   "metadata": {},
   "source": [
    "bez analizy atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ffc7e86a",
   "metadata": {},
   "source": [
    "# Podział zbioru na uczący i testowy w proporcji 70:30\n",
    "df_lrn_and_test1 = divide(df, 0.3)\n",
    "df_dscr_lrn1 = df_lrn_and_test1['dscr_lrn']\n",
    "df_dscr_test1 = df_lrn_and_test1['dscr_test']\n",
    "df_dec_lrn1 = df_lrn_and_test1['dec_lrn']\n",
    "df_dec_test1 = df_lrn_and_test1['dec_test']\n",
    "\n",
    "print('Liczba obiektów zbioru uczącego: ', len(df_dscr_lrn1))\n",
    "print('Liczba obiektów zbioru testowego: ', len(df_dscr_test1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0ea700f3",
   "metadata": {},
   "source": [
    "#Lista wszystkich atrybutów\n",
    "atr_list1 = list(range(df.shape[1]-1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42f8a8df",
   "metadata": {},
   "source": [
    "z analizą atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c84d4c3d",
   "metadata": {},
   "source": [
    "# Podział zbioru na uczący i testowy w proporcji 70:30\n",
    "df_lrn_and_test2 = divide(df_reduced, 0.3)\n",
    "df_dscr_lrn2 = df_lrn_and_test2['dscr_lrn']\n",
    "df_dscr_test2 = df_lrn_and_test2['dscr_test']\n",
    "df_dec_lrn2 = df_lrn_and_test2['dec_lrn']\n",
    "df_dec_test2 = df_lrn_and_test2['dec_test']\n",
    "\n",
    "print('Liczba obiektów zbioru uczącego: ', len(df_dscr_lrn2))\n",
    "print('Liczba obiektów zbioru testowego: ', len(df_dscr_test2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "192d90aa",
   "metadata": {},
   "source": [
    "#Lista wszystkich atrybutów\n",
    "atr_list2 = list(range(df_reduced.shape[1]-1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d049d85e",
   "metadata": {},
   "source": [
    "#### Naiwny klasyfikator Bayesa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d762318",
   "metadata": {},
   "source": [
    "# Tworzenie modelu naiwnego klasyfikatora Bayesa (wszystkie cechy)\n",
    "bayes1 = GaussianNB()\n",
    "\n",
    "verify(bayes1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, atr_list1)\n",
    "lims(bayes1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "bayes1.fit(df_dscr_lrn1, df_dec_lrn1)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = bayes1.predict(df_dscr_test1)\n",
    "accuracy = accuracy_score(df_dec_test1, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test1, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc8a1995",
   "metadata": {},
   "source": [
    "# Tworzenie modelu naiwnego klasyfikatora Bayesa (wybrane cechy)\n",
    "bayes2 = GaussianNB()\n",
    "\n",
    "verify(bayes2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, atr_list2)\n",
    "lims(bayes2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "bayes2.fit(df_dscr_lrn2, df_dec_lrn2)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = bayes2.predict(df_dscr_test2)\n",
    "accuracy = accuracy_score(df_dec_test2, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test2, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "641d7662",
   "metadata": {},
   "source": [
    "#### Las losowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3e0b4621",
   "metadata": {},
   "source": [
    "# Tworzenie modelu lasu losowego (wszystkie cechy)\n",
    "randomForest1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "verify(randomForest1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, atr_list1)\n",
    "lims(randomForest1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "randomForest1.fit(df_dscr_lrn1, df_dec_lrn1)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = randomForest1.predict(df_dscr_test1)\n",
    "accuracy = accuracy_score(df_dec_test1, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test1, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "291d94bd",
   "metadata": {},
   "source": [
    "# Tworzenie modelu lasu losowego (wybrane cechy)\n",
    "randomForest2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "verify(randomForest2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, atr_list2)\n",
    "lims(randomForest2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "randomForest2.fit(df_dscr_lrn2, df_dec_lrn2)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = randomForest2.predict(df_dscr_test2)\n",
    "accuracy = accuracy_score(df_dec_test2, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test2, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c13e4e9",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "47719156",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Tworzenie modelu XGBoost (wszystkie cechy)\n",
    "xgb_model1 = XGBClassifier()\n",
    "\n",
    "verify(xgb_model1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, atr_list1)\n",
    "lims(xgb_model1, df_dscr_lrn1, df_dscr_test1, df_dec_lrn1, df_dec_test1, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "xgb_model1.fit(df_dscr_lrn1, df_dec_lrn1)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = xgb_model1.predict(df_dscr_test1)\n",
    "accuracy = accuracy_score(df_dec_test1, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test1, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "29e7cfc4",
   "metadata": {},
   "source": [
    "# Tworzenie modelu XGBoost (wybrane cechy)\n",
    "xgb_model2 = XGBClassifier()\n",
    "\n",
    "verify(xgb_model2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, atr_list2)\n",
    "lims(xgb_model2, df_dscr_lrn2, df_dscr_test2, df_dec_lrn2, df_dec_test2, 0, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "xgb_model2.fit(df_dscr_lrn2, df_dec_lrn2)\n",
    "\n",
    "# Ocena wydajności modelu\n",
    "y_pred = xgb_model2.predict(df_dscr_test2)\n",
    "accuracy = accuracy_score(df_dec_test2, y_pred)\n",
    "print(\"Dokładność modelu:\", accuracy)\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_report(df_dec_test2, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "07849e23",
   "metadata": {},
   "source": [
    "Po przeanalizowaniu wszystkich wyników klasyfikacji, wybieram Las Losowy dla zredukowanych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "81095152",
   "metadata": {},
   "source": [
    "# Zapisanie modelu\n",
    "import pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(randomForest2, file)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
